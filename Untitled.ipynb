{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0541f23-882c-4782-aa98-e10163951a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65531b17-4c47-4cbf-bbd3-57c2ac4c3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "      tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(3, activation = 'softmax'),\n",
    "    ])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f1ddea6-9bdb-4625-b009-3712cc6f2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = create_model()\n",
    "model_1.load_weights(\"model_original.h5\")\n",
    "\n",
    "model_2 = create_model()\n",
    "model_2.load_weights(\"model_pruned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529f162-74ee-4fc6-89e7-a78572115a58",
   "metadata": {},
   "source": [
    "# Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dc99db00-24be-408f-9144-5b12278285e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo quantizado salvo em model_fixed_q15.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG FIXED-POINT\n",
    "# ============================================================\n",
    "Q = 15\n",
    "S = 1 << Q      # 32768\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARREGAR MODELO ORIGINAL .H5\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# 2. EXTRAIR PESOS FP32\n",
    "# ============================================================\n",
    "weights = model_1.get_weights()\n",
    "\n",
    "# Em um MLP típico:\n",
    "# camada 0: W0, b0\n",
    "# camada 1: W1, b1\n",
    "# camada 2: W2, b2\n",
    "#\n",
    "# Mas vamos generalizar: sempre pares (W, b)\n",
    "\n",
    "layers = []\n",
    "i = 0\n",
    "while i < len(weights):\n",
    "    W = weights[i]      # (inputs, outputs)\n",
    "    b = weights[i + 1]  # (outputs)\n",
    "    layers.append((W, b))\n",
    "    i += 2\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONVERTER PARA INT16 EM Q15 (SEM ESCALAS FLOAT)\n",
    "# ============================================================\n",
    "model_fixed = {\"layers\": []}\n",
    "\n",
    "for (Wf, bf) in layers:\n",
    "\n",
    "    # converter tensores FP32 → INT16 (Q15)\n",
    "    W_int16 = np.clip(np.round(Wf * S), -32768, 32767).astype(np.int16)\n",
    "    b_int16 = np.clip(np.round(bf * S), -32768, 32767).astype(np.int16)\n",
    "\n",
    "    layer_dict = {\n",
    "        \"W\": W_int16.tolist(),\n",
    "        \"b\": b_int16.tolist(),\n",
    "        \"Q\": Q\n",
    "    }\n",
    "\n",
    "    model_fixed[\"layers\"].append(layer_dict)\n",
    "\n",
    "# ============================================================\n",
    "# 4. SALVAR JSON FINAL (100% INTEIRO, SEM FLOAT)\n",
    "# ============================================================\n",
    "with open(\"model_fixed_q15.json\", \"w\") as f:\n",
    "    json.dump(model_fixed, f, indent=4)\n",
    "\n",
    "print(\"\\nModelo quantizado salvo em model_fixed_q15.json\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8b4c92c9-a74f-4ea0-9062-992e2e0e21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_fixed(x_q, W_q, b_q, Q, apply_relu=False):\n",
    "    \"\"\"\n",
    "    x_q: list/array de inteiros representam entrada em Q format (Q bits frac.)\n",
    "    W_q: lista (in_dim x out_dim) de inteiros (já em Q)\n",
    "    b_q: lista (out_dim) de inteiros (já em Q)\n",
    "    apply_relu: se True, aplica ReLU (em fixed-point, inteiros)\n",
    "    Retorna: lista de inteiros em Q\n",
    "    \"\"\"\n",
    "    in_dim = len(x_q)\n",
    "    out_dim = len(b_q)\n",
    "    out = [0] * out_dim\n",
    "\n",
    "    for j in range(out_dim):\n",
    "        acc = 0\n",
    "        # Note: W_q is shape (in_dim, out_dim) as produced acima\n",
    "        for i in range(in_dim):\n",
    "            wi = int(W_q[i][j])\n",
    "            xi = int(x_q[i])\n",
    "            acc += xi * wi   # int32 * int32 => pode precisar de int64 em Python / FPGA\n",
    "        acc += int(b_q[j])    # bias já em Q\n",
    "        # shift para voltar de Q+Q -> Q (já que xi and wi are Q each)\n",
    "        # mas aqui: xi and wi are both in Q, product is Q*2 -> >> Q returns Q\n",
    "        y_q = acc >> Q\n",
    "\n",
    "        if apply_relu:\n",
    "            if y_q < 0:\n",
    "                y_q = 0\n",
    "        out[j] = int(y_q)\n",
    "    return out\n",
    "\n",
    "def forward_fixed_with_activations(model_fixed, x_float):\n",
    "    \"\"\"\n",
    "    model_fixed: structure loaded from JSON with layers: [{\"W\":..,\"b\":..,\"Q\":..}, ...]\n",
    "    x_float: input in float (e.g. [5.1, 3.5, 1.4, 0.2])\n",
    "    Returns:\n",
    "      y_q_final: final outputs in integer Q format\n",
    "      y_float_probs: softmax probabilities computed in float (for verification)\n",
    "    \"\"\"\n",
    "    # quantize input to Q\n",
    "    x_q = [int(round(v * S)) for v in x_float]\n",
    "\n",
    "    # Layer 0: Dense + ReLU\n",
    "    # Layer 1: Dense + ReLU\n",
    "    # Layer 2: Dense + Softmax (no ReLU)\n",
    "    x = x_q\n",
    "    for li, layer in enumerate(model_fixed[\"layers\"]):\n",
    "        W = layer[\"W\"]\n",
    "        b = layer[\"b\"]\n",
    "        Q_layer = layer[\"Q\"]\n",
    "        # apply ReLU on layers except last\n",
    "        is_last = (li == len(model_fixed[\"layers\"]) - 1)\n",
    "        x = dense_fixed(x, W, b, Q_layer, apply_relu=(not is_last))\n",
    "        # x remains in Q format\n",
    "\n",
    "    y_q_final = x  # final output in Q\n",
    "\n",
    "    # For probabilities: convert final Q -> float and apply softmax in float\n",
    "    y_float = np.array([v / float(S) for v in y_q_final], dtype=float)\n",
    "    # numerical stable softmax\n",
    "    y_float_stable = y_float - np.max(y_float)\n",
    "    exp = np.exp(y_float_stable)\n",
    "    probs = exp / np.sum(exp)\n",
    "\n",
    "    return y_q_final, probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c940d598-3e69-4c07-ade8-19f96cda0696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 0\n",
      "46 0\n",
      "47 0\n",
      "48 0\n",
      "49 0\n",
      "50 1\n",
      "51 1\n",
      "52 1\n",
      "53 2\n",
      "54 2\n",
      "55 2\n",
      "56 2\n",
      "57 1\n",
      "58 1\n",
      "59 2\n",
      "60 2\n",
      "61 1\n",
      "62 1\n",
      "63 2\n",
      "64 1\n",
      "65 1\n",
      "66 2\n",
      "67 1\n",
      "68 2\n",
      "69 1\n",
      "70 2\n",
      "71 1\n",
      "72 2\n",
      "73 2\n",
      "74 1\n",
      "75 1\n",
      "76 2\n",
      "77 2\n",
      "78 2\n",
      "79 1\n",
      "80 1\n",
      "81 1\n",
      "82 1\n",
      "83 2\n",
      "84 2\n",
      "85 1\n",
      "86 1\n",
      "87 2\n",
      "88 1\n",
      "89 2\n",
      "90 2\n",
      "91 2\n",
      "92 1\n",
      "93 1\n",
      "94 2\n",
      "95 1\n",
      "96 1\n",
      "97 1\n",
      "98 1\n",
      "99 1\n",
      "100 2\n",
      "101 2\n",
      "102 2\n",
      "103 2\n",
      "104 2\n",
      "105 2\n",
      "106 2\n",
      "107 2\n",
      "108 2\n",
      "109 2\n",
      "110 2\n",
      "111 2\n",
      "112 2\n",
      "113 2\n",
      "114 2\n",
      "115 2\n",
      "116 2\n",
      "117 2\n",
      "118 2\n",
      "119 2\n",
      "120 2\n",
      "121 2\n",
      "122 2\n",
      "123 2\n",
      "124 2\n",
      "125 2\n",
      "126 2\n",
      "127 2\n",
      "128 2\n",
      "129 2\n",
      "130 2\n",
      "131 2\n",
      "132 2\n",
      "133 2\n",
      "134 2\n",
      "135 2\n",
      "136 2\n",
      "137 2\n",
      "138 2\n",
      "139 2\n",
      "140 2\n",
      "141 2\n",
      "142 2\n",
      "143 2\n",
      "144 2\n",
      "145 2\n",
      "146 2\n",
      "147 2\n",
      "148 2\n",
      "149 2\n"
     ]
    }
   ],
   "source": [
    "x_test = [5.1, 3.5, 1.4, 0.2]\n",
    "with open(\"model_fixed_q15.json\") as f:\n",
    "    model_q15 = json.load(f)\n",
    "    \n",
    "for i,x_test in enumerate(df.values):\n",
    "    y_q_final, probs = forward_fixed_with_activations(model_q15, x_test)\n",
    "    maior_valor = max(probs)\n",
    "    indice_maior = probs.index(maior_valor)\n",
    "    print(i,indice_maior)\n",
    "    #print(\"Entrada (float):\", x_test)\n",
    "    #print(\"Entrada (Q15):\", [int(round(v * S)) for v in x_test])\n",
    "    #print(\"Saída final (Q15 integers):\", y_q_final)\n",
    "    #print(\"Saída final convertida para float (antes do softmax):\", [v / float(S) for v in y_q_final])\n",
    "    \n",
    "    #print(i,\"Softmax (probabilidades):\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0df9a4f2-b4a8-4420-9f59-bdc80ff7e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167117, 114688, 45875, 6554]\n",
      "[160563, 98304, 45875, 6554]\n",
      "[154010, 104858, 42598, 6554]\n",
      "[150733, 101581, 49152, 6554]\n",
      "[163840, 117965, 45875, 6554]\n",
      "[176947, 127795, 55706, 13107]\n",
      "[150733, 111411, 45875, 9830]\n",
      "[163840, 111411, 49152, 6554]\n",
      "[144179, 95027, 45875, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[176947, 121242, 49152, 6554]\n",
      "[157286, 111411, 52429, 6554]\n",
      "[157286, 98304, 45875, 3277]\n",
      "[140902, 98304, 36045, 3277]\n",
      "[190054, 131072, 39322, 6554]\n",
      "[186778, 144179, 49152, 13107]\n",
      "[176947, 127795, 42598, 13107]\n",
      "[167117, 114688, 45875, 9830]\n",
      "[186778, 124518, 55706, 9830]\n",
      "[167117, 124518, 49152, 9830]\n",
      "[176947, 111411, 55706, 6554]\n",
      "[167117, 121242, 49152, 13107]\n",
      "[150733, 117965, 32768, 6554]\n",
      "[167117, 108134, 55706, 16384]\n",
      "[157286, 111411, 62259, 6554]\n",
      "[163840, 98304, 52429, 6554]\n",
      "[163840, 111411, 52429, 13107]\n",
      "[170394, 114688, 49152, 6554]\n",
      "[170394, 111411, 45875, 6554]\n",
      "[154010, 104858, 52429, 6554]\n",
      "[157286, 101581, 52429, 6554]\n",
      "[176947, 111411, 49152, 13107]\n",
      "[170394, 134349, 49152, 3277]\n",
      "[180224, 137626, 45875, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[163840, 104858, 39322, 6554]\n",
      "[180224, 114688, 42598, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[144179, 98304, 42598, 6554]\n",
      "[167117, 111411, 49152, 6554]\n",
      "[163840, 114688, 42598, 9830]\n",
      "[147456, 75366, 42598, 9830]\n",
      "[144179, 104858, 42598, 6554]\n",
      "[163840, 114688, 52429, 19661]\n",
      "[167117, 124518, 62259, 13107]\n",
      "[157286, 98304, 45875, 9830]\n",
      "[167117, 124518, 52429, 6554]\n",
      "[150733, 104858, 45875, 6554]\n",
      "[173670, 121242, 49152, 6554]\n",
      "[163840, 108134, 45875, 6554]\n",
      "[229376, 104858, 154010, 45875]\n",
      "[209715, 104858, 147456, 49152]\n",
      "[226099, 101581, 160563, 49152]\n",
      "[180224, 75366, 131072, 42598]\n",
      "[212992, 91750, 150733, 49152]\n",
      "[186778, 91750, 147456, 42598]\n",
      "[206438, 108134, 154010, 52429]\n",
      "[160563, 78643, 108134, 32768]\n",
      "[216269, 95027, 150733, 42598]\n",
      "[170394, 88474, 127795, 45875]\n",
      "[163840, 65536, 114688, 32768]\n",
      "[193331, 98304, 137626, 49152]\n",
      "[196608, 72090, 131072, 32768]\n",
      "[199885, 95027, 154010, 45875]\n",
      "[183501, 95027, 117965, 42598]\n",
      "[219546, 101581, 144179, 45875]\n",
      "[183501, 98304, 147456, 49152]\n",
      "[190054, 88474, 134349, 32768]\n",
      "[203162, 72090, 147456, 49152]\n",
      "[183501, 81920, 127795, 36045]\n",
      "[193331, 104858, 157286, 58982]\n",
      "[199885, 91750, 131072, 42598]\n",
      "[206438, 81920, 160563, 49152]\n",
      "[199885, 91750, 154010, 39322]\n",
      "[209715, 95027, 140902, 42598]\n",
      "[216269, 98304, 144179, 45875]\n",
      "[222822, 91750, 157286, 45875]\n",
      "[219546, 98304, 163840, 55706]\n",
      "[196608, 95027, 147456, 49152]\n",
      "[186778, 85197, 114688, 32768]\n",
      "[180224, 78643, 124518, 36045]\n",
      "[180224, 78643, 121242, 32768]\n",
      "[190054, 88474, 127795, 39322]\n",
      "[196608, 88474, 167117, 52429]\n",
      "[176947, 98304, 147456, 49152]\n",
      "[196608, 111411, 147456, 52429]\n",
      "[219546, 101581, 154010, 49152]\n",
      "[206438, 75366, 144179, 42598]\n",
      "[183501, 98304, 134349, 42598]\n",
      "[180224, 81920, 131072, 42598]\n",
      "[180224, 85197, 144179, 39322]\n",
      "[199885, 98304, 150733, 45875]\n",
      "[190054, 85197, 131072, 39322]\n",
      "[163840, 75366, 108134, 32768]\n",
      "[183501, 88474, 137626, 42598]\n",
      "[186778, 98304, 137626, 39322]\n",
      "[186778, 95027, 137626, 42598]\n",
      "[203162, 95027, 140902, 42598]\n",
      "[167117, 81920, 98304, 36045]\n",
      "[186778, 91750, 134349, 42598]\n",
      "[206438, 108134, 196608, 81920]\n",
      "[190054, 88474, 167117, 62259]\n",
      "[232653, 98304, 193331, 68813]\n",
      "[206438, 95027, 183501, 58982]\n",
      "[212992, 98304, 190054, 72090]\n",
      "[249037, 98304, 216269, 68813]\n",
      "[160563, 81920, 147456, 55706]\n",
      "[239206, 95027, 206438, 58982]\n",
      "[219546, 81920, 190054, 58982]\n",
      "[235930, 117965, 199885, 81920]\n",
      "[212992, 104858, 167117, 65536]\n",
      "[209715, 88474, 173670, 62259]\n",
      "[222822, 98304, 180224, 68813]\n",
      "[186778, 81920, 163840, 65536]\n",
      "[190054, 91750, 167117, 78643]\n",
      "[209715, 104858, 173670, 75366]\n",
      "[212992, 98304, 180224, 58982]\n",
      "[252314, 124518, 219546, 72090]\n",
      "[252314, 85197, 226099, 75366]\n",
      "[196608, 72090, 163840, 49152]\n",
      "[226099, 104858, 186778, 75366]\n",
      "[183501, 91750, 160563, 65536]\n",
      "[252314, 91750, 219546, 65536]\n",
      "[206438, 88474, 160563, 58982]\n",
      "[219546, 108134, 186778, 68813]\n",
      "[235930, 104858, 196608, 58982]\n",
      "[203162, 91750, 157286, 58982]\n",
      "[199885, 98304, 160563, 58982]\n",
      "[209715, 91750, 183501, 68813]\n",
      "[235930, 98304, 190054, 52429]\n",
      "[242483, 91750, 199885, 62259]\n",
      "[258867, 124518, 209715, 65536]\n",
      "[209715, 91750, 183501, 72090]\n",
      "[206438, 91750, 167117, 49152]\n",
      "[199885, 85197, 183501, 45875]\n",
      "[252314, 98304, 199885, 75366]\n",
      "[206438, 111411, 183501, 78643]\n",
      "[209715, 101581, 180224, 58982]\n",
      "[196608, 98304, 157286, 58982]\n",
      "[226099, 101581, 176947, 68813]\n",
      "[219546, 101581, 183501, 78643]\n",
      "[226099, 101581, 167117, 75366]\n",
      "[190054, 88474, 167117, 62259]\n",
      "[222822, 104858, 193331, 75366]\n",
      "[219546, 108134, 186778, 81920]\n",
      "[219546, 98304, 170394, 75366]\n",
      "[206438, 81920, 163840, 62259]\n",
      "[212992, 98304, 170394, 65536]\n",
      "[203162, 111411, 176947, 75366]\n",
      "[193331, 98304, 167117, 58982]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
    "for inputs in df.values:\n",
    "    #print(v)\n",
    "    XX = [int(round(v * S)) for v in inputs]\n",
    "    print(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ca86719-1034-4012-82f6-8ba60b91f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': [[19664, 9150, -23742], [17410, 5808, 9579], [-5316, -6239, -921], [-11091, -17293, -12750], [-18056, 12197, 8456], [-3604, 12754, -11371], [-25862, 10387, 32488], [15457, 6670, -594], [17926, -14600, 3124], [30210, 24997, -32768]], 'b': [171, 3732, -3904], 'Q': 15}\n"
     ]
    }
   ],
   "source": [
    "with open(\"model_fixed_q15.json\") as f:\n",
    "    model_q15 = json.load(f)\n",
    "\n",
    "print(model_q15[\"layers\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ec46d0e-6b9e-41f2-a2ae-258914d9c05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quant_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 4. Test with your input\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m5.1\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m1.4\u001b[39m, \u001b[38;5;241m0.2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPGA-style output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnetwork_fpga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras output:     \u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mpredict(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[111], line 33\u001b[0m, in \u001b[0;36mnetwork_fpga\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnetwork_fpga\u001b[39m(x):\n\u001b[0;32m---> 33\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m run_layer_fpga_style(x, \u001b[43mquant_layers\u001b[49m[\u001b[38;5;241m0\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     out2 \u001b[38;5;241m=\u001b[39m run_layer_fpga_style(out1, quant_layers[\u001b[38;5;241m1\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m     out3 \u001b[38;5;241m=\u001b[39m run_layer_fpga_style(out2, quant_layers[\u001b[38;5;241m2\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quant_layers' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2afd7-5031-4463-8201-739f5891a692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3a14a-b9a7-48f2-9e26-09d1e4f6c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de9df3f-1e13-4aab-b437-ac177c53aadb",
   "metadata": {},
   "source": [
    "# Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4287c33a-d32d-4b9b-8f1c-eb1acfc97247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_0 = {{-0.604084, -0.43862638, -0.60887384, 0.14159617, 0.081027284, 0.8441983, -0.62555903, 0.03434454, 0.2334831, -0.308789}\n",
      "{-0.26546732, 0.09918172, -0.38273737, 0.85462046, 0.30392697, 0.8459995, 0.103014246, -0.36124212, -0.7498861, -0.5854438}\n",
      "{-0.42703894, 1.0414269, 0.27372074, 0.36178854, 0.052327693, -0.71919113, 0.66412246, 0.59268254, 0.68459153, 0.3554647}\n",
      "{-0.16218063, 0.34137863, -0.36495435, -0.1080789, -0.8303009, -0.7879873, 0.77219903, 0.5044243, 0.89198685, -0.62637246}}\n",
      "\n",
      "\n",
      "bias_1 = {0.0, -0.18442735, 0.0, 0.23999116, 0.2211163, 0.49307373, -0.22524667, -0.28398588, -0.26383048, 0.0}\n",
      "\n",
      "\n",
      "dense_2 = {{0.21553802, 0.04532814, 0.18782806, 0.04965788, -0.51238674, -0.32938683, -0.47236773, -0.17661834, -0.47334164, 0.23396271}\n",
      "{-0.3994535, -0.29037222, 0.22594579, 0.33456558, -0.014758025, -0.08547509, 0.82613987, -0.46504357, -0.00979102, -0.25520575}\n",
      "{-0.20166588, 0.3411448, -0.23639762, -0.40582216, 0.106350005, 0.058526218, 0.3475421, -0.27237234, -0.14449021, 0.15036261}\n",
      "{-0.0072580734, -0.26433796, -0.24726477, -0.16061315, 0.1476835, -0.51110566, 0.27242938, 0.2788709, -0.067329764, 0.8348188}\n",
      "{0.31783015, -0.48351988, -0.3843444, -0.027688563, -0.08070716, 0.36803168, -0.5109253, 0.049039192, -0.065133594, 0.45548043}\n",
      "{0.9001637, -0.28698152, 0.49032092, -0.37319782, -0.07434711, 0.06643009, -0.084653005, 0.060448315, 0.62449753, 1.0954702}\n",
      "{-0.055407483, 0.11215109, 0.3336292, -0.32913586, -0.41583425, -0.5116648, 0.31993803, -0.009328231, -0.043183483, -0.6016562}\n",
      "{-0.31379008, 0.1037128, 0.46047762, -0.17054772, 0.57672995, -0.36519545, 0.54386646, -0.37867528, -0.3767386, -0.6553896}\n",
      "{0.0046965755, -0.37405083, 0.38998362, -0.48435315, 0.66566014, 0.006950915, 0.70984834, 0.006968047, -0.55757624, -0.8591063}\n",
      "{0.38966984, -0.25015932, -0.09516898, 0.5254029, -0.35389286, -0.40345174, 0.2393915, 0.020548701, 0.39711827, 0.53991795}}\n",
      "\n",
      "\n",
      "bias_3 = {0.14753656, 0.0, -0.042555276, 0.0, 0.07236309, 0.0, -0.082184866, 0.019035634, 0.06663764, 0.37827012}\n",
      "\n",
      "\n",
      "dense_4 = {{0.6000829, 0.27924633, -0.7245538}\n",
      "{0.5313263, 0.17724681, 0.29233617}\n",
      "{-0.16222271, -0.1904037, -0.02809496}\n",
      "{-0.3384727, -0.52774346, -0.3890878}\n",
      "{-0.55102175, 0.37223408, 0.25804478}\n",
      "{-0.10997516, 0.3892138, -0.34700692}\n",
      "{-0.789246, 0.3169815, 0.99145496}\n",
      "{0.47170725, 0.20354307, -0.018137284}\n",
      "{0.5470543, -0.44554427, 0.09533974}\n",
      "{0.92193276, 0.7628468, -1.286511}}\n",
      "\n",
      "\n",
      "bias_5 = {0.0052289553, 0.11390424, -0.11913329}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,layer in enumerate(model_1.trainable_variables):\n",
    "    if len(layer.shape) == 2:\n",
    "        layer_name = f\"dense_{k}\"\n",
    "    else:\n",
    "        layer_name = f\"bias_{k}\"\n",
    "    print(layer_name, end=\" = \")\n",
    "    if len(layer.shape) == 2:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            print(\"{\", end='')\n",
    "            for j in range(layer.shape[1]):\n",
    "                if j == layer.shape[1]-1:\n",
    "                    print(layer[i][j].numpy(), end='')\n",
    "                    if i == layer.shape[0]-1:\n",
    "                        print(\"}\", end=\"\")\n",
    "                    else:\n",
    "                        print(\"}\")\n",
    "                else:\n",
    "                    print(layer[i][j].numpy(), end=', ')\n",
    "\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(\"}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif len(layer.shape) == 1:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(layer[i].numpy(), end='')\n",
    "            else:\n",
    "                print(layer[i].numpy(), end=', ')\n",
    "        print(\"}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28097f6-7a2a-4335-9a1c-c627fc6b17f6",
   "metadata": {},
   "source": [
    "# Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed83a6bd-c1ec-452c-8b3b-3e8f320e5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_0 = {{-0.0, 0.0, 0.0, 0.0, 0.0, -0.46895635, -0.54173553, -0.0, 1.4024988, -0.0}\n",
      "{-0.48098794, 0.65235287, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9575694, -0.0, -0.0}\n",
      "{-0.0, 0.48658806, 0.0, 1.5404005, -0.49930173, 0.0, 0.0, -0.0, -0.0, 0.6410306}\n",
      "{-0.0, -0.0, 0.0, 1.3764648, 0.0, -0.5344521, 0.5897832, 0.7647514, -0.0, 0.0}}\n",
      "\n",
      "\n",
      "bias_1 = {-0.0, 0.0, 0.0, -1.0695125, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0}\n",
      "\n",
      "\n",
      "dense_2 = {{0.3828769, -0.4501102, -0.43758386, 0.3456546, 0.0, 0.37987673, -0.42665458, 0.0, 0.0, 0.0}\n",
      "{-0.3751071, -0.0, 0.0, -0.49813116, -0.3551431, -0.0, -0.0, -0.5158035, 0.0, 0.0}\n",
      "{0.3707428, 0.0, 0.0, 0.37650466, 0.39439058, 0.0, 0.44521958, -0.3974523, 0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0, 0.49818254, 0.0, -0.0, 0.0, 0.7899263, 0.31250882, 2.095871}\n",
      "{0.0, -0.43435535, -0.39177608, 0.0, 0.0, 0.379448, 0.0, -0.43082505, 0.0, 0.0}\n",
      "{0.0, 0.0, 0.0, 0.0, 0.29803532, 0.4495368, 0.0, 0.0, 0.49408722, -0.45457926}\n",
      "{0.0, 0.52600265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}\n",
      "{-0.5356419, 0.0, -0.3005587, 0.0, 0.0, -0.0, 0.0, -0.35917524, 0.0, 1.1606073}\n",
      "{-0.0, -0.0, 0.0, 0.0, 0.0, 1.3124079, -0.0, -0.0, -0.48029333, -0.6621637}\n",
      "{-0.0, 0.3831486, 0.0, 0.0, -0.52803457, -0.0, -0.0, 0.38902563, -0.39296597, 0.0}}\n",
      "\n",
      "\n",
      "bias_3 = {-0.0, -0.0, 0.0, 0.0, 0.0, 0.8782468, -0.0, -0.0, 0.0, 0.0}\n",
      "\n",
      "\n",
      "dense_4 = {{-0.6698825, 0.642372, -0.624045}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.5925772, -0.6351959, 0.0}\n",
      "{1.1442233, 0.5313083, -1.309763}\n",
      "{0.0, 0.51840836, 0.5634494}\n",
      "{-0.70193714, -0.0, 0.0}\n",
      "{0.0, 0.0, 0.6430756}\n",
      "{-1.4147238, -0.0, 1.8186651}}\n",
      "\n",
      "\n",
      "bias_5 = {0.2808141, -0.0, -0.57344407}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,layer in enumerate(model_2.trainable_variables):\n",
    "    if len(layer.shape) == 2:\n",
    "        layer_name = f\"dense_{k}\"\n",
    "    else:\n",
    "        layer_name = f\"bias_{k}\"\n",
    "    print(layer_name, end=\" = \")\n",
    "    if len(layer.shape) == 2:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            print(\"{\", end='')\n",
    "            for j in range(layer.shape[1]):\n",
    "                if j == layer.shape[1]-1:\n",
    "                    print(layer[i][j].numpy(), end='')\n",
    "                    if i == layer.shape[0]-1:\n",
    "                        print(\"}\", end=\"\")\n",
    "                    else:\n",
    "                        print(\"}\")\n",
    "                else:\n",
    "                    print(layer[i][j].numpy(), end=', ')\n",
    "\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(\"}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif len(layer.shape) == 1:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(layer[i].numpy(), end='')\n",
    "            else:\n",
    "                print(layer[i].numpy(), end=', ')\n",
    "        print(\"}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c29409-e7e5-438a-a6ef-3341e1fdddd5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
