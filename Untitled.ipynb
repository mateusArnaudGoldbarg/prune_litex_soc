{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0541f23-882c-4782-aa98-e10163951a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:41:05.791587: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 21:41:06.580960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:06.581027: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-12-18 21:41:08.890973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:08.891140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:08.891154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65531b17-4c47-4cbf-bbd3-57c2ac4c3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(4,)),\n",
    "      tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "      tf.keras.layers.Dense(3, activation = 'softmax'),\n",
    "    ])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1ddea6-9bdb-4625-b009-3712cc6f2651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:41:12.106569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-12-18 21:41:12.107373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-12-18 21:41:12.107959: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-12-18 21:41:12.109339: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_1 = create_model()\n",
    "model_1.load_weights(\"model_original.h5\")\n",
    "\n",
    "model_2 = create_model()\n",
    "model_2.load_weights(\"model_pruned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529f162-74ee-4fc6-89e7-a78572115a58",
   "metadata": {},
   "source": [
    "# Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc99db00-24be-408f-9144-5b12278285e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo quantizado salvo em model_fixed_q15.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG FIXED-POINT\n",
    "# ============================================================\n",
    "Q = 15\n",
    "S = 1 << Q      # 32768\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARREGAR MODELO ORIGINAL .H5\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# 2. EXTRAIR PESOS FP32\n",
    "# ============================================================\n",
    "weights = model_1.get_weights()\n",
    "\n",
    "# Em um MLP típico:\n",
    "# camada 0: W0, b0\n",
    "# camada 1: W1, b1\n",
    "# camada 2: W2, b2\n",
    "#\n",
    "# Mas vamos generalizar: sempre pares (W, b)\n",
    "\n",
    "layers = []\n",
    "i = 0\n",
    "while i < len(weights):\n",
    "    W = weights[i]      # (inputs, outputs)\n",
    "    b = weights[i + 1]  # (outputs)\n",
    "    layers.append((W, b))\n",
    "    i += 2\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONVERTER PARA INT16 EM Q15 (SEM ESCALAS FLOAT)\n",
    "# ============================================================\n",
    "model_fixed = {\"layers\": []}\n",
    "\n",
    "for (Wf, bf) in layers:\n",
    "\n",
    "    # converter tensores FP32 → INT16 (Q15)\n",
    "    W_int16 = np.clip(np.round(Wf * S), -32768, 32767).astype(np.int16)\n",
    "    b_int16 = np.clip(np.round(bf * S), -32768, 32767).astype(np.int16)\n",
    "\n",
    "    layer_dict = {\n",
    "        \"W\": W_int16.tolist(),\n",
    "        \"b\": b_int16.tolist(),\n",
    "        \"Q\": Q\n",
    "    }\n",
    "\n",
    "    model_fixed[\"layers\"].append(layer_dict)\n",
    "\n",
    "# ============================================================\n",
    "# 4. SALVAR JSON FINAL (100% INTEIRO, SEM FLOAT)\n",
    "# ============================================================\n",
    "with open(\"model_fixed_q15.json\", \"w\") as f:\n",
    "    json.dump(model_fixed, f, indent=4)\n",
    "\n",
    "print(\"\\nModelo quantizado salvo em model_fixed_q15.json\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4c92c9-a74f-4ea0-9062-992e2e0e21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_fixed(x_q, W_q, b_q, Q, apply_relu=False):\n",
    "    \"\"\"\n",
    "    x_q: list/array de inteiros representam entrada em Q format (Q bits frac.)\n",
    "    W_q: lista (in_dim x out_dim) de inteiros (já em Q)\n",
    "    b_q: lista (out_dim) de inteiros (já em Q)\n",
    "    apply_relu: se True, aplica ReLU (em fixed-point, inteiros)\n",
    "    Retorna: lista de inteiros em Q\n",
    "    \"\"\"\n",
    "    in_dim = len(x_q)\n",
    "    out_dim = len(b_q)\n",
    "    out = [0] * out_dim\n",
    "\n",
    "    for j in range(out_dim):\n",
    "        acc = 0\n",
    "        # Note: W_q is shape (in_dim, out_dim) as produced acima\n",
    "        for i in range(in_dim):\n",
    "            wi = int(W_q[i][j])\n",
    "            xi = int(x_q[i])\n",
    "            acc += xi * wi   # int32 * int32 => pode precisar de int64 em Python / FPGA\n",
    "        acc += int(b_q[j])    # bias já em Q\n",
    "        # shift para voltar de Q+Q -> Q (já que xi and wi are Q each)\n",
    "        # mas aqui: xi and wi are both in Q, product is Q*2 -> >> Q returns Q\n",
    "        y_q = acc >> Q\n",
    "\n",
    "        if apply_relu:\n",
    "            if y_q < 0:\n",
    "                y_q = 0\n",
    "        out[j] = int(y_q)\n",
    "    return out\n",
    "\n",
    "def forward_fixed_with_activations(model_fixed, x_float):\n",
    "    \"\"\"\n",
    "    model_fixed: structure loaded from JSON with layers: [{\"W\":..,\"b\":..,\"Q\":..}, ...]\n",
    "    x_float: input in float (e.g. [5.1, 3.5, 1.4, 0.2])\n",
    "    Returns:\n",
    "      y_q_final: final outputs in integer Q format\n",
    "      y_float_probs: softmax probabilities computed in float (for verification)\n",
    "    \"\"\"\n",
    "    # quantize input to Q\n",
    "    x_q = [int(round(v * S)) for v in x_float]\n",
    "\n",
    "    # Layer 0: Dense + ReLU\n",
    "    # Layer 1: Dense + ReLU\n",
    "    # Layer 2: Dense + Softmax (no ReLU)\n",
    "    x = x_q\n",
    "    for li, layer in enumerate(model_fixed[\"layers\"]):\n",
    "        W = layer[\"W\"]\n",
    "        b = layer[\"b\"]\n",
    "        Q_layer = layer[\"Q\"]\n",
    "        # apply ReLU on layers except last\n",
    "        is_last = (li == len(model_fixed[\"layers\"]) - 1)\n",
    "        x = dense_fixed(x, W, b, Q_layer, apply_relu=(not is_last))\n",
    "        # x remains in Q format\n",
    "\n",
    "    y_q_final = x  # final output in Q\n",
    "\n",
    "    # For probabilities: convert final Q -> float and apply softmax in float\n",
    "    y_float = np.array([v / float(S) for v in y_q_final], dtype=float)\n",
    "    # numerical stable softmax\n",
    "    y_float_stable = y_float - np.max(y_float)\n",
    "    exp = np.exp(y_float_stable)\n",
    "    probs = exp / np.sum(exp)\n",
    "\n",
    "    return y_q_final, probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c940d598-3e69-4c07-ade8-19f96cda0696",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_fixed_q15.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     model_q15 \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,x_test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m      6\u001b[0m     y_q_final, probs \u001b[38;5;241m=\u001b[39m forward_fixed_with_activations(model_q15, x_test)\n\u001b[1;32m      7\u001b[0m     maior_valor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(probs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = [5.1, 3.5, 1.4, 0.2]\n",
    "with open(\"model_fixed_q15.json\") as f:\n",
    "    model_q15 = json.load(f)\n",
    "    \n",
    "for i,x_test in enumerate(df.values):\n",
    "    y_q_final, probs = forward_fixed_with_activations(model_q15, x_test)\n",
    "    maior_valor = max(probs)\n",
    "    indice_maior = probs.index(maior_valor)\n",
    "    print(i,indice_maior)\n",
    "    #print(\"Entrada (float):\", x_test)\n",
    "    #print(\"Entrada (Q15):\", [int(round(v * S)) for v in x_test])\n",
    "    #print(\"Saída final (Q15 integers):\", y_q_final)\n",
    "    #print(\"Saída final convertida para float (antes do softmax):\", [v / float(S) for v in y_q_final])\n",
    "    \n",
    "    #print(i,\"Softmax (probabilidades):\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df9a4f2-b4a8-4420-9f59-bdc80ff7e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167117, 114688, 45875, 6554]\n",
      "[160563, 98304, 45875, 6554]\n",
      "[154010, 104858, 42598, 6554]\n",
      "[150733, 101581, 49152, 6554]\n",
      "[163840, 117965, 45875, 6554]\n",
      "[176947, 127795, 55706, 13107]\n",
      "[150733, 111411, 45875, 9830]\n",
      "[163840, 111411, 49152, 6554]\n",
      "[144179, 95027, 45875, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[176947, 121242, 49152, 6554]\n",
      "[157286, 111411, 52429, 6554]\n",
      "[157286, 98304, 45875, 3277]\n",
      "[140902, 98304, 36045, 3277]\n",
      "[190054, 131072, 39322, 6554]\n",
      "[186778, 144179, 49152, 13107]\n",
      "[176947, 127795, 42598, 13107]\n",
      "[167117, 114688, 45875, 9830]\n",
      "[186778, 124518, 55706, 9830]\n",
      "[167117, 124518, 49152, 9830]\n",
      "[176947, 111411, 55706, 6554]\n",
      "[167117, 121242, 49152, 13107]\n",
      "[150733, 117965, 32768, 6554]\n",
      "[167117, 108134, 55706, 16384]\n",
      "[157286, 111411, 62259, 6554]\n",
      "[163840, 98304, 52429, 6554]\n",
      "[163840, 111411, 52429, 13107]\n",
      "[170394, 114688, 49152, 6554]\n",
      "[170394, 111411, 45875, 6554]\n",
      "[154010, 104858, 52429, 6554]\n",
      "[157286, 101581, 52429, 6554]\n",
      "[176947, 111411, 49152, 13107]\n",
      "[170394, 134349, 49152, 3277]\n",
      "[180224, 137626, 45875, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[163840, 104858, 39322, 6554]\n",
      "[180224, 114688, 42598, 6554]\n",
      "[160563, 101581, 49152, 3277]\n",
      "[144179, 98304, 42598, 6554]\n",
      "[167117, 111411, 49152, 6554]\n",
      "[163840, 114688, 42598, 9830]\n",
      "[147456, 75366, 42598, 9830]\n",
      "[144179, 104858, 42598, 6554]\n",
      "[163840, 114688, 52429, 19661]\n",
      "[167117, 124518, 62259, 13107]\n",
      "[157286, 98304, 45875, 9830]\n",
      "[167117, 124518, 52429, 6554]\n",
      "[150733, 104858, 45875, 6554]\n",
      "[173670, 121242, 49152, 6554]\n",
      "[163840, 108134, 45875, 6554]\n",
      "[229376, 104858, 154010, 45875]\n",
      "[209715, 104858, 147456, 49152]\n",
      "[226099, 101581, 160563, 49152]\n",
      "[180224, 75366, 131072, 42598]\n",
      "[212992, 91750, 150733, 49152]\n",
      "[186778, 91750, 147456, 42598]\n",
      "[206438, 108134, 154010, 52429]\n",
      "[160563, 78643, 108134, 32768]\n",
      "[216269, 95027, 150733, 42598]\n",
      "[170394, 88474, 127795, 45875]\n",
      "[163840, 65536, 114688, 32768]\n",
      "[193331, 98304, 137626, 49152]\n",
      "[196608, 72090, 131072, 32768]\n",
      "[199885, 95027, 154010, 45875]\n",
      "[183501, 95027, 117965, 42598]\n",
      "[219546, 101581, 144179, 45875]\n",
      "[183501, 98304, 147456, 49152]\n",
      "[190054, 88474, 134349, 32768]\n",
      "[203162, 72090, 147456, 49152]\n",
      "[183501, 81920, 127795, 36045]\n",
      "[193331, 104858, 157286, 58982]\n",
      "[199885, 91750, 131072, 42598]\n",
      "[206438, 81920, 160563, 49152]\n",
      "[199885, 91750, 154010, 39322]\n",
      "[209715, 95027, 140902, 42598]\n",
      "[216269, 98304, 144179, 45875]\n",
      "[222822, 91750, 157286, 45875]\n",
      "[219546, 98304, 163840, 55706]\n",
      "[196608, 95027, 147456, 49152]\n",
      "[186778, 85197, 114688, 32768]\n",
      "[180224, 78643, 124518, 36045]\n",
      "[180224, 78643, 121242, 32768]\n",
      "[190054, 88474, 127795, 39322]\n",
      "[196608, 88474, 167117, 52429]\n",
      "[176947, 98304, 147456, 49152]\n",
      "[196608, 111411, 147456, 52429]\n",
      "[219546, 101581, 154010, 49152]\n",
      "[206438, 75366, 144179, 42598]\n",
      "[183501, 98304, 134349, 42598]\n",
      "[180224, 81920, 131072, 42598]\n",
      "[180224, 85197, 144179, 39322]\n",
      "[199885, 98304, 150733, 45875]\n",
      "[190054, 85197, 131072, 39322]\n",
      "[163840, 75366, 108134, 32768]\n",
      "[183501, 88474, 137626, 42598]\n",
      "[186778, 98304, 137626, 39322]\n",
      "[186778, 95027, 137626, 42598]\n",
      "[203162, 95027, 140902, 42598]\n",
      "[167117, 81920, 98304, 36045]\n",
      "[186778, 91750, 134349, 42598]\n",
      "[206438, 108134, 196608, 81920]\n",
      "[190054, 88474, 167117, 62259]\n",
      "[232653, 98304, 193331, 68813]\n",
      "[206438, 95027, 183501, 58982]\n",
      "[212992, 98304, 190054, 72090]\n",
      "[249037, 98304, 216269, 68813]\n",
      "[160563, 81920, 147456, 55706]\n",
      "[239206, 95027, 206438, 58982]\n",
      "[219546, 81920, 190054, 58982]\n",
      "[235930, 117965, 199885, 81920]\n",
      "[212992, 104858, 167117, 65536]\n",
      "[209715, 88474, 173670, 62259]\n",
      "[222822, 98304, 180224, 68813]\n",
      "[186778, 81920, 163840, 65536]\n",
      "[190054, 91750, 167117, 78643]\n",
      "[209715, 104858, 173670, 75366]\n",
      "[212992, 98304, 180224, 58982]\n",
      "[252314, 124518, 219546, 72090]\n",
      "[252314, 85197, 226099, 75366]\n",
      "[196608, 72090, 163840, 49152]\n",
      "[226099, 104858, 186778, 75366]\n",
      "[183501, 91750, 160563, 65536]\n",
      "[252314, 91750, 219546, 65536]\n",
      "[206438, 88474, 160563, 58982]\n",
      "[219546, 108134, 186778, 68813]\n",
      "[235930, 104858, 196608, 58982]\n",
      "[203162, 91750, 157286, 58982]\n",
      "[199885, 98304, 160563, 58982]\n",
      "[209715, 91750, 183501, 68813]\n",
      "[235930, 98304, 190054, 52429]\n",
      "[242483, 91750, 199885, 62259]\n",
      "[258867, 124518, 209715, 65536]\n",
      "[209715, 91750, 183501, 72090]\n",
      "[206438, 91750, 167117, 49152]\n",
      "[199885, 85197, 183501, 45875]\n",
      "[252314, 98304, 199885, 75366]\n",
      "[206438, 111411, 183501, 78643]\n",
      "[209715, 101581, 180224, 58982]\n",
      "[196608, 98304, 157286, 58982]\n",
      "[226099, 101581, 176947, 68813]\n",
      "[219546, 101581, 183501, 78643]\n",
      "[226099, 101581, 167117, 75366]\n",
      "[190054, 88474, 167117, 62259]\n",
      "[222822, 104858, 193331, 75366]\n",
      "[219546, 108134, 186778, 81920]\n",
      "[219546, 98304, 170394, 75366]\n",
      "[206438, 81920, 163840, 62259]\n",
      "[212992, 98304, 170394, 65536]\n",
      "[203162, 111411, 176947, 75366]\n",
      "[193331, 98304, 167117, 58982]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n",
    "for inputs in df.values:\n",
    "    #print(v)\n",
    "    XX = [int(round(v * S)) for v in inputs]\n",
    "    print(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca86719-1034-4012-82f6-8ba60b91f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-19795, -14373, -19952, 4640, 2655, 27663, -20498, 1125, 7651, -10118], [-8699, 3250, -12542, 28004, 9959, 27722, 3376, -11837, -24572, -19184], [-13993, 32767, 8969, 11855, 1715, -23566, 21762, 19421, 22433, 11648], [-5314, 11186, -11959, -3542, -27207, -25821, 25303, 16529, 29229, -20525]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"model_fixed_q15.json\") as f:\n",
    "    model_q15 = json.load(f)\n",
    "\n",
    "print(model_q15[\"layers\"][0]['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec46d0e-6b9e-41f2-a2ae-258914d9c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2afd7-5031-4463-8201-739f5891a692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3a14a-b9a7-48f2-9e26-09d1e4f6c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de9df3f-1e13-4aab-b437-ac177c53aadb",
   "metadata": {},
   "source": [
    "# Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4287c33a-d32d-4b9b-8f1c-eb1acfc97247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_0 = {{-0.604084, -0.43862638, -0.60887384, 0.14159617, 0.081027284, 0.8441983, -0.62555903, 0.03434454, 0.2334831, -0.308789}\n",
      "{-0.26546732, 0.09918172, -0.38273737, 0.85462046, 0.30392697, 0.8459995, 0.103014246, -0.36124212, -0.7498861, -0.5854438}\n",
      "{-0.42703894, 1.0414269, 0.27372074, 0.36178854, 0.052327693, -0.71919113, 0.66412246, 0.59268254, 0.68459153, 0.3554647}\n",
      "{-0.16218063, 0.34137863, -0.36495435, -0.1080789, -0.8303009, -0.7879873, 0.77219903, 0.5044243, 0.89198685, -0.62637246}}\n",
      "\n",
      "\n",
      "bias_1 = {0.0, -0.18442735, 0.0, 0.23999116, 0.2211163, 0.49307373, -0.22524667, -0.28398588, -0.26383048, 0.0}\n",
      "\n",
      "\n",
      "dense_2 = {{0.21553802, 0.04532814, 0.18782806, 0.04965788, -0.51238674, -0.32938683, -0.47236773, -0.17661834, -0.47334164, 0.23396271}\n",
      "{-0.3994535, -0.29037222, 0.22594579, 0.33456558, -0.014758025, -0.08547509, 0.82613987, -0.46504357, -0.00979102, -0.25520575}\n",
      "{-0.20166588, 0.3411448, -0.23639762, -0.40582216, 0.106350005, 0.058526218, 0.3475421, -0.27237234, -0.14449021, 0.15036261}\n",
      "{-0.0072580734, -0.26433796, -0.24726477, -0.16061315, 0.1476835, -0.51110566, 0.27242938, 0.2788709, -0.067329764, 0.8348188}\n",
      "{0.31783015, -0.48351988, -0.3843444, -0.027688563, -0.08070716, 0.36803168, -0.5109253, 0.049039192, -0.065133594, 0.45548043}\n",
      "{0.9001637, -0.28698152, 0.49032092, -0.37319782, -0.07434711, 0.06643009, -0.084653005, 0.060448315, 0.62449753, 1.0954702}\n",
      "{-0.055407483, 0.11215109, 0.3336292, -0.32913586, -0.41583425, -0.5116648, 0.31993803, -0.009328231, -0.043183483, -0.6016562}\n",
      "{-0.31379008, 0.1037128, 0.46047762, -0.17054772, 0.57672995, -0.36519545, 0.54386646, -0.37867528, -0.3767386, -0.6553896}\n",
      "{0.0046965755, -0.37405083, 0.38998362, -0.48435315, 0.66566014, 0.006950915, 0.70984834, 0.006968047, -0.55757624, -0.8591063}\n",
      "{0.38966984, -0.25015932, -0.09516898, 0.5254029, -0.35389286, -0.40345174, 0.2393915, 0.020548701, 0.39711827, 0.53991795}}\n",
      "\n",
      "\n",
      "bias_3 = {0.14753656, 0.0, -0.042555276, 0.0, 0.07236309, 0.0, -0.082184866, 0.019035634, 0.06663764, 0.37827012}\n",
      "\n",
      "\n",
      "dense_4 = {{0.6000829, 0.27924633, -0.7245538}\n",
      "{0.5313263, 0.17724681, 0.29233617}\n",
      "{-0.16222271, -0.1904037, -0.02809496}\n",
      "{-0.3384727, -0.52774346, -0.3890878}\n",
      "{-0.55102175, 0.37223408, 0.25804478}\n",
      "{-0.10997516, 0.3892138, -0.34700692}\n",
      "{-0.789246, 0.3169815, 0.99145496}\n",
      "{0.47170725, 0.20354307, -0.018137284}\n",
      "{0.5470543, -0.44554427, 0.09533974}\n",
      "{0.92193276, 0.7628468, -1.286511}}\n",
      "\n",
      "\n",
      "bias_5 = {0.0052289553, 0.11390424, -0.11913329}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,layer in enumerate(model_1.trainable_variables):\n",
    "    if len(layer.shape) == 2:\n",
    "        layer_name = f\"dense_{k}\"\n",
    "    else:\n",
    "        layer_name = f\"bias_{k}\"\n",
    "    print(layer_name, end=\" = \")\n",
    "    if len(layer.shape) == 2:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            print(\"{\", end='')\n",
    "            for j in range(layer.shape[1]):\n",
    "                if j == layer.shape[1]-1:\n",
    "                    print(layer[i][j].numpy(), end='')\n",
    "                    if i == layer.shape[0]-1:\n",
    "                        print(\"}\", end=\"\")\n",
    "                    else:\n",
    "                        print(\"}\")\n",
    "                else:\n",
    "                    print(layer[i][j].numpy(), end=', ')\n",
    "\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(\"}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif len(layer.shape) == 1:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(layer[i].numpy(), end='')\n",
    "            else:\n",
    "                print(layer[i].numpy(), end=', ')\n",
    "        print(\"}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28097f6-7a2a-4335-9a1c-c627fc6b17f6",
   "metadata": {},
   "source": [
    "# Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef5ebf6-a1bb-40ec-8547-a6a69ceefa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo quantizado salvo em model_fixed_q15.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG FIXED-POINT\n",
    "# ============================================================\n",
    "Q = 15\n",
    "S = 1 << Q      # 32768\n",
    "\n",
    "# ============================================================\n",
    "# 1. CARREGAR MODELO ORIGINAL .H5\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# 2. EXTRAIR PESOS FP32\n",
    "# ============================================================\n",
    "weights = model_2.get_weights()\n",
    "\n",
    "# Em um MLP típico:\n",
    "# camada 0: W0, b0\n",
    "# camada 1: W1, b1\n",
    "# camada 2: W2, b2\n",
    "#\n",
    "# Mas vamos generalizar: sempre pares (W, b)\n",
    "\n",
    "layers = []\n",
    "i = 0\n",
    "while i < len(weights):\n",
    "    W = weights[i]      # (inputs, outputs)\n",
    "    b = weights[i + 1]  # (outputs)\n",
    "    layers.append((W, b))\n",
    "    i += 2\n",
    "\n",
    "# ============================================================\n",
    "# 3. CONVERTER PARA INT16 EM Q15 (SEM ESCALAS FLOAT)\n",
    "# ============================================================\n",
    "model_fixed = {\"layers\": []}\n",
    "\n",
    "for (Wf, bf) in layers:\n",
    "\n",
    "    # converter tensores FP32 → INT16 (Q15)\n",
    "    W_int16 = np.clip(np.round(Wf * S), -32768, 32767).astype(np.int16)\n",
    "    b_int16 = np.clip(np.round(bf * S), -32768, 32767).astype(np.int16)\n",
    "\n",
    "    layer_dict = {\n",
    "        \"W\": W_int16.tolist(),\n",
    "        \"b\": b_int16.tolist(),\n",
    "        \"Q\": Q\n",
    "    }\n",
    "\n",
    "    model_fixed[\"layers\"].append(layer_dict)\n",
    "\n",
    "# ============================================================\n",
    "# 4. SALVAR JSON FINAL (100% INTEIRO, SEM FLOAT)\n",
    "# ============================================================\n",
    "with open(\"model_pruned_fixed_q15.json\", \"w\") as f:\n",
    "    json.dump(model_fixed, f, indent=4)\n",
    "\n",
    "print(\"\\nModelo quantizado salvo em model_fixed_q15.json\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29345c42-5ec4-4357-8c7c-4c6cd197630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, -15367, -17752, 0, 32767, 0], [-15761, 21376, 0, 0, 0, 0, 0, -31378, 0, 0], [0, 15945, 0, 32767, -16361, 0, 0, 0, 0, 21005], [0, 0, 0, 32767, 0, -17513, 19326, 25059, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"model_pruned_fixed_q15.json\") as f:\n",
    "    model_q15 = json.load(f)\n",
    "\n",
    "print(model_q15[\"layers\"][0]['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cc8d0e-c25d-4bfa-b77e-ea705193905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, -15367, -17752, 0, 32767, 0], [-15761, 21376, 0, 0, 0, 0, 0, -31378, 0, 0], [0, 15945, 0, 32767, -16361, 0, 0, 0, 0, 21005], [0, 0, 0, 32767, 0, -17513, 19326, 25059, 0, 0]]\n",
      "[[12546, -14749, -14339, 11326, 0, 12448, -13981, 0, 0, 0], [-12292, 0, 0, -16323, -11637, 0, 0, -16902, 0, 0], [12148, 0, 0, 12337, 12923, 0, 14589, -13024, 0, 0], [0, 0, 0, 16324, 0, 0, 0, 25884, 10240, 32767], [0, -14233, -12838, 0, 0, 12434, 0, -14117, 0, 0], [0, 0, 0, 0, 9766, 14730, 0, 0, 16190, -14896], [0, 17236, 0, 0, 0, 0, 0, 0, 0, 0], [-17552, 0, -9849, 0, 0, 0, 0, -11769, 0, 32767], [0, 0, 0, 0, 0, 32767, 0, 0, -15738, -21698], [0, 12555, 0, 0, -17303, 0, 0, 12748, -12877, 0]]\n",
      "[[-21951, 21049, -20449], [0, 0, 0], [0, 0, 0], [0, 0, 0], [-19418, -20814, 0], [32767, 17410, -32768], [0, 16987, 18463], [-23001, 0, 0], [0, 0, 21072], [-32768, 0, 32767]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(model_q15[\"layers\"][i]['W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be255697-c392-4f88-bf73-e903358b1e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-21951, -19418, 32767, -23001, -32768, \n",
      "0, 4, 5, 7, 9, \n",
      "1\n",
      "21049, -20814, 17410, 16987, \n",
      "0, 4, 5, 6, \n",
      "2\n",
      "-20449, -32768, 18463, 21072, 32767, \n",
      "0, 5, 6, 8, 9, \n"
     ]
    }
   ],
   "source": [
    "a = np.array(model_q15[\"layers\"][2]['W'])\n",
    "\n",
    "#print(a)\n",
    "for i in range(a.shape[1]):\n",
    "    coluna = a[:, i]\n",
    "    print(i)\n",
    "    #print(f\"Coluna {i}: {coluna}\")\n",
    "    for b,j in enumerate(coluna):\n",
    "        if j != 0:\n",
    "            print(j, end=\", \")\n",
    "    print()\n",
    "    for b,j in enumerate(coluna):\n",
    "        if j != 0:\n",
    "            print(b, end=\", \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac0eba-348c-4f1c-8584-762a75a40430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126c2a2-d64a-4b84-b166-d6072f191a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a764f6-3d58-41f5-a735-f7cb55cf938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7053c-9f9a-4cce-b096-1400fe6d2f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0425787-24ec-4c7b-a7ab-5611af3d18c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b77bc-0a6f-4386-bf59-7a960c89f2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc4ee2-3529-4a34-9989-b80c1a99917f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28635429-6370-4759-b9aa-56bfb5119ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81404916-faf7-4032-82eb-be521bd399bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed83a6bd-c1ec-452c-8b3b-3e8f320e5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_0 = {{-0.0, 0.0, 0.0, 0.0, 0.0, -0.46895635, -0.54173553, -0.0, 1.4024988, -0.0}\n",
      "{-0.48098794, 0.65235287, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9575694, -0.0, -0.0}\n",
      "{-0.0, 0.48658806, 0.0, 1.5404005, -0.49930173, 0.0, 0.0, -0.0, -0.0, 0.6410306}\n",
      "{-0.0, -0.0, 0.0, 1.3764648, 0.0, -0.5344521, 0.5897832, 0.7647514, -0.0, 0.0}}\n",
      "\n",
      "\n",
      "bias_1 = {-0.0, 0.0, 0.0, -1.0695125, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0}\n",
      "\n",
      "\n",
      "dense_2 = {{0.3828769, -0.4501102, -0.43758386, 0.3456546, 0.0, 0.37987673, -0.42665458, 0.0, 0.0, 0.0}\n",
      "{-0.3751071, -0.0, 0.0, -0.49813116, -0.3551431, -0.0, -0.0, -0.5158035, 0.0, 0.0}\n",
      "{0.3707428, 0.0, 0.0, 0.37650466, 0.39439058, 0.0, 0.44521958, -0.3974523, 0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0, 0.49818254, 0.0, -0.0, 0.0, 0.7899263, 0.31250882, 2.095871}\n",
      "{0.0, -0.43435535, -0.39177608, 0.0, 0.0, 0.379448, 0.0, -0.43082505, 0.0, 0.0}\n",
      "{0.0, 0.0, 0.0, 0.0, 0.29803532, 0.4495368, 0.0, 0.0, 0.49408722, -0.45457926}\n",
      "{0.0, 0.52600265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0}\n",
      "{-0.5356419, 0.0, -0.3005587, 0.0, 0.0, -0.0, 0.0, -0.35917524, 0.0, 1.1606073}\n",
      "{-0.0, -0.0, 0.0, 0.0, 0.0, 1.3124079, -0.0, -0.0, -0.48029333, -0.6621637}\n",
      "{-0.0, 0.3831486, 0.0, 0.0, -0.52803457, -0.0, -0.0, 0.38902563, -0.39296597, 0.0}}\n",
      "\n",
      "\n",
      "bias_3 = {-0.0, -0.0, 0.0, 0.0, 0.0, 0.8782468, -0.0, -0.0, 0.0, 0.0}\n",
      "\n",
      "\n",
      "dense_4 = {{-0.6698825, 0.642372, -0.624045}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.0, -0.0, 0.0}\n",
      "{-0.5925772, -0.6351959, 0.0}\n",
      "{1.1442233, 0.5313083, -1.309763}\n",
      "{0.0, 0.51840836, 0.5634494}\n",
      "{-0.70193714, -0.0, 0.0}\n",
      "{0.0, 0.0, 0.6430756}\n",
      "{-1.4147238, -0.0, 1.8186651}}\n",
      "\n",
      "\n",
      "bias_5 = {0.2808141, -0.0, -0.57344407}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,layer in enumerate(model_2.trainable_variables):\n",
    "    if len(layer.shape) == 2:\n",
    "        layer_name = f\"dense_{k}\"\n",
    "    else:\n",
    "        layer_name = f\"bias_{k}\"\n",
    "    print(layer_name, end=\" = \")\n",
    "    if len(layer.shape) == 2:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            print(\"{\", end='')\n",
    "            for j in range(layer.shape[1]):\n",
    "                if j == layer.shape[1]-1:\n",
    "                    print(layer[i][j].numpy(), end='')\n",
    "                    if i == layer.shape[0]-1:\n",
    "                        print(\"}\", end=\"\")\n",
    "                    else:\n",
    "                        print(\"}\")\n",
    "                else:\n",
    "                    print(layer[i][j].numpy(), end=', ')\n",
    "\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(\"}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif len(layer.shape) == 1:\n",
    "        print(\"{\", end='')\n",
    "        for i in range(layer.shape[0]):\n",
    "            if i == layer.shape[0]-1:\n",
    "                print(layer[i].numpy(), end='')\n",
    "            else:\n",
    "                print(layer[i].numpy(), end=', ')\n",
    "        print(\"}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c29409-e7e5-438a-a6ef-3341e1fdddd5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
